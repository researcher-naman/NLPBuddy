{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c14f0c6-3484-4c45-a212-fc37478d101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention, Bidirectional, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea0c974-11f0-46b9-aa0a-f01710b18787",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"semeval2014.csv\")\n",
    "\n",
    "# Encode polarity labels (positive=2, neutral=1, negative=0)\n",
    "label_encoder = LabelEncoder()\n",
    "data['polarity'] = label_encoder.fit_transform(data['polarity'])\n",
    "\n",
    "# Tokenize text and aspects\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['Sentence'])\n",
    "review_sequences = tokenizer.texts_to_sequences(data['Sentence'])\n",
    "aspect_sequences = tokenizer.texts_to_sequences(data['Aspect Term'])\n",
    "\n",
    "# Pad sequences\n",
    "max_seq_len = 100  # Maximum length for reviews\n",
    "review_padded = pad_sequences(review_sequences, maxlen=max_seq_len, padding='post', truncating='post')\n",
    "aspect_padded = pad_sequences(aspect_sequences, maxlen=max_seq_len, padding='post', truncating='post')\n",
    "labels = tf.keras.utils.to_categorical(data['polarity'], num_classes=4)\n",
    "\n",
    "train_reviews, test_reviews, train_aspects, test_aspects, train_labels, test_labels = train_test_split(\n",
    "    review_padded, aspect_padded, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e763f0a-cebb-4b47-8fa5-5a0c343c8f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\naman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_1']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.3839 - loss: 1.1994 - val_accuracy: 0.4025 - val_loss: 1.1359\n",
      "Epoch 2/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.4593 - loss: 1.0837 - val_accuracy: 0.6250 - val_loss: 0.9391\n",
      "Epoch 3/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7121 - loss: 0.7471 - val_accuracy: 0.6737 - val_loss: 0.8299\n",
      "Epoch 4/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.8282 - loss: 0.5091 - val_accuracy: 0.7055 - val_loss: 0.8104\n",
      "Epoch 5/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.8650 - loss: 0.3910 - val_accuracy: 0.7076 - val_loss: 0.8803\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7413 - loss: 0.7996\n",
      "Test Loss: 0.8803200125694275\n",
      "Test Accuracy: 0.7076271176338196\n"
     ]
    }
   ],
   "source": [
    "from HubNLP import build_attention_model\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 10000  # You can use the tokenizer's word index size\n",
    "embedding_dim = 128\n",
    "max_seq_len = 100\n",
    "lstm_units = 64\n",
    "\n",
    "model = build_attention_model(vocab_size, embedding_dim, max_seq_len, lstm_units)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [train_reviews, train_aspects], \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size=32, \n",
    "    validation_data=([test_reviews, test_aspects], test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate([test_reviews, test_aspects], test_labels)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954b286-852c-4c0b-8b1f-3608b5b9993c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
